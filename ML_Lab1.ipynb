{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Lab1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1M5V6t3I58AdtqdpCdQG1kuqux6nmuKes",
      "authorship_tag": "ABX9TyMQq9gSLWilEdSYxGmc4Y18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shostina/ML/blob/main/ML_Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6mVZsGdsh6Q"
      },
      "source": [
        "This methods delete or replace punctuation emoticons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TibfqboeSl0y"
      },
      "source": [
        "emoticons = {\n",
        "    ':*': '<kiss>',\n",
        "    ':-*': '<kiss>',\n",
        "    ':x': '<kiss>',\n",
        "    ':-)': '<happy>',\n",
        "    ':-))': '<happy>',\n",
        "    ':-)))': '<happy>',\n",
        "    ':-))))': '<happy>',\n",
        "    ':-)))))': '<happy>',\n",
        "    ':-))))))': '<happy>',\n",
        "    ':)': '<happy>',\n",
        "    ':))': '<happy>',\n",
        "    ':)))': '<happy>',\n",
        "    ':))))': '<happy>',\n",
        "    ':)))))': '<happy>',\n",
        "    ':))))))': '<happy>',\n",
        "    ':)))))))': '<happy>',\n",
        "    ':o)': '<happy>',\n",
        "    ':]': '<happy>',\n",
        "    ':3': '<happy>',\n",
        "    ':c)': '<happy>',\n",
        "    ':>': '<happy>',\n",
        "    '=]': '<happy>',\n",
        "    '8)': '<happy>',\n",
        "    '=)': '<happy>',\n",
        "    ':}': '<happy>',\n",
        "    ':^)': '<happy>',\n",
        "    '|;-)': '<happy>',\n",
        "    \":'-)\": '<happy>',\n",
        "    \":')\": '<happy>',\n",
        "    '\\o/': '<happy>',\n",
        "    '*\\\\0/*': '<happy>',\n",
        "    ':-D': '<laugh>',\n",
        "    ':D': '<laugh>',\n",
        "    '8-D': '<laugh>',\n",
        "    '8D': '<laugh>',\n",
        "    'x-D': '<laugh>',\n",
        "    'xD': '<laugh>',\n",
        "    'X-D': '<laugh>',\n",
        "    'XD': '<laugh>',\n",
        "    '=-D': '<laugh>',\n",
        "    '=D': '<laugh>',\n",
        "    '=-3': '<laugh>',\n",
        "    '=3': '<laugh>',\n",
        "    'B^D': '<laugh>',\n",
        "    '>:[': '<sad>',\n",
        "    ':-(': '<sad>',\n",
        "    ':-((': '<sad>',\n",
        "    ':-(((': '<sad>',\n",
        "    ':-((((': '<sad>',\n",
        "    ':-(((((': '<sad>',\n",
        "    ':-((((((': '<sad>',\n",
        "    ':-(((((((': '<sad>',\n",
        "    ':(': '<sad>',\n",
        "    ':((': '<sad>',\n",
        "    ':(((': '<sad>',\n",
        "    ':((((': '<sad>',\n",
        "    ':(((((': '<sad>',\n",
        "    ':((((((': '<sad>',\n",
        "    ':(((((((': '<sad>',\n",
        "    ':((((((((': '<sad>',\n",
        "    ':-c': '<sad>',\n",
        "    ':c': '<sad>',\n",
        "    ':-<': '<sad>',\n",
        "    ':<': '<sad>',\n",
        "    ':-[': '<sad>',\n",
        "    ':[': '<sad>',\n",
        "    ':{': '<sad>',\n",
        "    ':-||': '<sad>',\n",
        "    ':@': '<sad>',\n",
        "    \":'-(\": '<sad>',\n",
        "    \":'(\": '<sad>',\n",
        "    'D:<': '<sad>',\n",
        "    'D:': '<sad>',\n",
        "    'D8': '<sad>',\n",
        "    'D;': '<sad>',\n",
        "    'D=': '<sad>',\n",
        "    'DX': '<sad>',\n",
        "    'v.v': '<sad>',\n",
        "    \"D-':\": '<sad>',\n",
        "    '(>_<)': '<sad>',\n",
        "    ':|': '<sad>',\n",
        "    '>:O': '<surprise>',\n",
        "    ':-O': '<surprise>',\n",
        "    ':-o': '<surprise>',\n",
        "    ':O': '<surprise>',\n",
        "    '°o°': '<surprise>',\n",
        "    'o_O': '<surprise>',\n",
        "    'o_0': '<surprise>',\n",
        "    'o.O': '<surprise>',\n",
        "    'o-o': '<surprise>',\n",
        "    '8-0': '<surprise>',\n",
        "    '|-O': '<surprise>',\n",
        "    ';-)': '<wink>',\n",
        "    ';)': '<wink>',\n",
        "    '*-)': '<wink>',\n",
        "    '*)': '<wink>',\n",
        "    ';-]': '<wink>',\n",
        "    ';]': '<wink>',\n",
        "    ';D': '<wink>',\n",
        "    ';^)': '<wink>',\n",
        "    ':-,': '<wink>',\n",
        "    '>:P': '<tong>',\n",
        "    ':-P': '<tong>',\n",
        "    ':P': '<tong>',\n",
        "    'X-P': '<tong>',\n",
        "    'x-p': '<tong>',\n",
        "    ':-p': '<tong>',\n",
        "    ':p': '<tong>',\n",
        "    '=p': '<tong>',\n",
        "    ':-Þ': '<tong>',\n",
        "    ':Þ': '<tong>',\n",
        "    ':-b': '<tong>',\n",
        "    ':b': '<tong>',\n",
        "    ':-&': '<tong>',\n",
        "    '>:\\\\': '<annoyed>',\n",
        "    '>:/': '<annoyed>',\n",
        "    ':-/': '<annoyed>',\n",
        "    ':-.': '<annoyed>',\n",
        "    ':/': '<annoyed>',\n",
        "    ':\\\\': '<annoyed>',\n",
        "    '=/': '<annoyed>',\n",
        "    '=\\\\': '<annoyed>',\n",
        "    ':L': '<annoyed>',\n",
        "    '=L': '<annoyed>',\n",
        "    ':S': '<annoyed>',\n",
        "    '>.<': '<annoyed>',\n",
        "    ':-|': '<annoyed>',\n",
        "    '<:-|': '<annoyed>',\n",
        "    ':-X': '<seallips>',\n",
        "    ':X': '<seallips>',\n",
        "    ':-#': '<seallips>',\n",
        "    ':#': '<seallips>',\n",
        "    'O:-)': '<angel>',\n",
        "    '0:-3': '<angel>',\n",
        "    '0:3': '<angel>',\n",
        "    '0:-)': '<angel>',\n",
        "    '0:)': '<angel>',\n",
        "    '0;^)': '<angel>',\n",
        "    '>:)': '<devil>',\n",
        "    '>:D': '<devil>',\n",
        "    '>:-D': '<devil>',\n",
        "    '>;)': '<devil>',\n",
        "    '>:-)': '<devil>',\n",
        "    '}:-)': '<devil>',\n",
        "    '}:)': '<devil>',\n",
        "    '3:-)': '<devil>',\n",
        "    '3:)': '<devil>',\n",
        "    'o/\\o': '<highfive>',\n",
        "    '^5': '<highfive>',\n",
        "    '>_>^': '<highfive>',\n",
        "    '^<_<': '<highfive>',\n",
        "    '<3': '<heart>',\n",
        "    '^3^': '<smile>',\n",
        "    \"(':\": '<smile>',\n",
        "    \" > < \": '<smile>',\n",
        "    \"UvU\": '<smile>',\n",
        "    \"uwu\": '<smile>',\n",
        "    'UwU': '<smile>'\n",
        "}\n",
        "def replace_emoticons(x):\n",
        "  for em in emoticons:\n",
        "    x = x.replace(em, emoticons[em][1:-1])\n",
        "  return x\n",
        "\n",
        "def delete_emoticons(x):\n",
        "  for em in emoticons:\n",
        "    x = x.replace(em, '')\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC5rOlKYrvIK"
      },
      "source": [
        "This method deletes url from twit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sa29gL5SWV9"
      },
      "source": [
        "def delete_url(x):\n",
        "    pattern_url = re.compile(\n",
        "        r\"\"\"(?xi)\\b(?:(?:https?|ftp|file)://|www\\.|ftp\\.|pic\\.|twitter\\.|facebook\\.)(?:\\([-A-Z0-9+&@#/%=~_|$?!:;,.]*\\)|[-A-Z0-9+&@#/%=~_|$?!:;,.])*(?:\\([-A-Z0-9+&@#\\/%=~_|$?!:,.]*\\)|[A-Z0-9+&@#\\/%=~_|$])\"\"\")\n",
        "    pattern_punc = re.compile(r\"[\\-\\\"`$%^&*(|)/~\\[\\]{}:;+,._='?!]+\")\n",
        "    return pattern_punc.sub('', pattern_url.sub('', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhqDBrdjsLZu"
      },
      "source": [
        "This method replace contraction form with full form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUZNoBqWrkXi"
      },
      "source": [
        "contraction_mapping = {\"’\":\"'\",\"RT \":\" \",\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"can not\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                       \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                       \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "                       \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\",\n",
        "                       \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\",\n",
        "                       \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\",\n",
        "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
        "                       \"it'll've\": \"it will have\",\"it's\": \"it is\", \"it’s\":\"it is\",\"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
        "                       \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "                       \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                       \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
        "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
        "                       \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
        "                       \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "                       \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
        "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
        "                       \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\",\n",
        "                       \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\n",
        "                       \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
        "                       \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "                       \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
        "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
        "                       \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
        "                       \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
        "                       \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
        "                       \"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
        "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" ,\"It's\":\"It is\",\"You'd\":\"You would\",\n",
        "                       ' u ':\" you \",'yrs':'years','FYI':'For your information',' im ':' I am ','lol':'LOL','You\\'re':'You are','can’t':'can not','…':'. ','...':'. ','\\'\\'':'\\'','≠':'','ain’t':'am not','I’m':'I am','RT\\'s':''}\n",
        "\n",
        "def fix_contraction(s):\n",
        "  for c in contraction_mapping:\n",
        "    s = s.replace(c, contraction_mapping[c])\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjeY7yMKsz_C"
      },
      "source": [
        "There is load csv Test and Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHW_U4qLD-qs",
        "outputId": "1d70f4df-78bc-4844-db3f-fbd79b1014dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import argparse\n",
        "import codecs\n",
        "import sys\n",
        "import base64\n",
        "import csv\n",
        "import gzip\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "\n",
        "train_topic_res = []\n",
        "train_sentiment_res = []\n",
        "train_topic_data = []\n",
        "train_sentiment_data = []\n",
        "test_topic_res = []\n",
        "test_sentiment_res = []\n",
        "test_topic_data = []\n",
        "test_sentiment_data = []\n",
        "\n",
        "with open(\"Train.csv\") as train_f:\n",
        "    line = train_f.readline()\n",
        "    for line in train_f:\n",
        "        #line = line.decode(\"utf-8\", errors='replace')\n",
        "        fields = line.rstrip('\\n').replace('\"','').split(',')\n",
        "        train_topic_res.append(fields[0])\n",
        "        train_topic_data.append(delete_url(delete_emoticons(fields[3])))\n",
        "        if fields[1] != 'irrelevant':\n",
        "          train_sentiment_res.append(fields[1])\n",
        "          train_sentiment_data.append(replace_emoticons(fix_contraction(delete_url(fields[3]))))\n",
        "print(\"Ready with read train\")\n",
        "\n",
        "with open(\"Test.csv\") as test_f:\n",
        "    line = test_f.readline()\n",
        "    for line in test_f:\n",
        "        fields = line.rstrip('\\n').replace('\"','').split(',')\n",
        "        test_topic_res.append(fields[0])\n",
        "        test_topic_data.append(delete_url(delete_emoticons(fields[3])))\n",
        "        if fields[1] != 'irrelevant':\n",
        "          test_sentiment_res.append(fields[1])\n",
        "          test_sentiment_data.append(replace_emoticons(fix_contraction(delete_url(fields[3]))))\n",
        "print(\"Ready with read test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready with read train\n",
            "Ready with read test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBZAhagktlK9"
      },
      "source": [
        "There is topic classificator training. Was used linear classificator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtfOelG-EXBW",
        "outputId": "63b7fecb-2759-4694-9946-05641f88e8c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "pipeline_topic = Pipeline([('tfidf', TfidfVectorizer()), ('clf', clf)])\n",
        "pipeline_topic.fit(train_topic_data, train_topic_res)\n",
        "print(\"Ready with fit topic\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready with fit topic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lf8Lswujxm"
      },
      "source": [
        "There is sentiment classificator training. Was used linear classificator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VddiCYTOGDLt",
        "outputId": "aa65ce7e-977a-44d2-b460-6589dfa62d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "clf = LinearSVC()\n",
        "pipeline_sentiment = Pipeline([('tfidf', TfidfVectorizer()), ('clf', clf)])\n",
        "pipeline_sentiment.fit(train_sentiment_data, train_sentiment_res)\n",
        "print(\"Ready with fit sentiment\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ready with fit sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIfRX0aour_6"
      },
      "source": [
        "There is topic predictions and classification report. F-mara is 0.77"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_eyq8Z7EXQi",
        "outputId": "2c840e8f-711f-42c1-f720-5db6ea898159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "topic_predictions = pipeline_topic.predict(test_topic_data)\n",
        "print(classification_report(test_topic_res, topic_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       apple       0.91      0.83      0.87        98\n",
            "      google       0.79      0.75      0.77        79\n",
            "   microsoft       0.74      0.69      0.72        78\n",
            "     twitter       0.66      0.79      0.72        87\n",
            "\n",
            "    accuracy                           0.77       342\n",
            "   macro avg       0.77      0.76      0.77       342\n",
            "weighted avg       0.78      0.77      0.77       342\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnHsxbOLurXz"
      },
      "source": [
        "There is sentiment predictions and classification report. F-mera is 0.64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7COHGsOkK9To",
        "outputId": "085d9778-b43d-4f01-848a-ed35c3e878fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "sentiment_predictions = pipeline_sentiment.predict(test_sentiment_data)\n",
        "print(classification_report(test_sentiment_res, sentiment_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.69      0.49      0.57        49\n",
            "     neutral       0.77      0.90      0.83       156\n",
            "    positive       0.65      0.41      0.50        32\n",
            "\n",
            "    accuracy                           0.75       237\n",
            "   macro avg       0.70      0.60      0.64       237\n",
            "weighted avg       0.74      0.75      0.73       237\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeRK8Qv5wVCK"
      },
      "source": [
        "Interface to classify new twit. Please replace twit to your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4OtUMKxvdh6",
        "outputId": "218fcde8-deef-431d-ada7-14dbe9b64072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "twit = 'Apple company does ...'\n",
        "print('Topic is:', *(pipeline_topic.predict([twit])))\n",
        "twit = 'This burger is very good :)'\n",
        "print('Sentiment is:', *(pipeline_sentiment.predict([twit])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic is: apple\n",
            "Sentiment is: positive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
